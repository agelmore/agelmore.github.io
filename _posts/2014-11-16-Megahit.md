---
layout: post
title:  "Megahit"
date:   2014-11-16
comments: true
---

[Megahit](https://github.com/voutcn/megahit) is a relatively new NGS assembler that can *de novo* assemble very large data sets from metagenomic samples. I used it to assemble the [synthetic metadata](https://export.uppmax.uu.se/b2010008/projects-public/concoct-paper-data/) that I've been playing with from the CONCOCT paper published in *Nature Methods* by [Alneburg et al.](http://www-ncbi-nlm-nih-gov.proxy.lib.umich.edu/pubmed/?term=binning+metagenomic+contigs+by+coverage+and+composition). 

Titas Brown says that megahit is [pretty good](http://ivory.idyll.org/blog/2014-how-good-is-megahit.html) and it is faster and more memory efficient. Digital normalization is not needed. I cloned megahit into /mnt/EXT/Schloss-data/amanda/Fuso/megahit/megahit. It's pretty simple to use. It will take fasta, fastq, or zipped files. I don't think it can take paired read information.


