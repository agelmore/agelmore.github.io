---
layout: post
title:  "CONCOCT synthetic data"
date:   2014-11-24
comments: true
---

While I'm waiting for the assemblies to finish, I'm going to go back and post some info that I haven't talked about before. First, what is all this data I'm assembling?

In the [CONCOCT paper](http://www-ncbi-nlm-nih-gov.proxy.lib.umich.edu/pubmed/?term=binning+metagenomic+contigs+by+coverage+and+composition), Alneburg et al. use two synthetic mock metagenomic data sets (can be found [here](https://export.uppmax.uu.se/b2010008/projects-public/concoct-paper-data/)). The first called "species" has 101 species that were identified from HMP data using 16S. Once the organisms were chosen, they compiled all the chromosome and plasmid information from NCBI for those 101 genomes. They also created a second data set that included fewer organisms (20 organisms abundant in the gut), but these include multiple strains of E.coli, Bacteroides, and Clostridium. In both datasets the frequencies of the organisms were similar to frequencies in the HMP. 

From these large genome compilations, Alneburg et al. similulated reads that would be obtained from an Illumina HiSeq. The species mock has 96 samples with 7.75 million paired-end reads each. The strain mock has 64 samples with 11.75 million paired-end reads each (~2GB per sample). This is small compared to the HMP samples which can reach 69 million reads. In the simulated reads they included error profiles from a real data set. 

The species dataset is what I've been trying to assemble in the previous posts. 

Dataset | # of species | # of samples | reads per sample | read format
-------- | -------- | -------- | -------- | --------
Species | 101 | 96 | 7.75 million | fasta
Strain | 20 | 64 | 11.75 million | fasta
